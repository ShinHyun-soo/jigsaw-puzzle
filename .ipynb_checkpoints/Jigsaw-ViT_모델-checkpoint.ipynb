{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_zEOOEy-vPU",
    "outputId": "fd90054b-077e-4296-81bd-dedd45fa955c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwqI2wbO-2xE"
   },
   "outputs": [],
   "source": [
    "!mkdir DATA\n",
    "!unzip -qq {'/content/drive/MyDrive/DACON/open.zip'} -d /content/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77Jw9fnH9nZr",
    "outputId": "56196dea-b647-4e0c-f076-acfb553f3449"
   },
   "outputs": [],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZcUPEAQ_9Sub"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bMWBz-ExGOLi"
   },
   "outputs": [],
   "source": [
    "def calc_puzzle(answer_df, submission_df):\n",
    "    # Check for missing values in submission_df\n",
    "    if submission_df.isnull().values.any():\n",
    "        raise ValueError(\"The submission dataframe contains missing values.\")\n",
    "\n",
    "    # Public or Private answer Sample and Sorting by 'ID'\n",
    "    submission_df = submission_df[submission_df.iloc[:, 0].isin(answer_df.iloc[:, 0])]\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    # Check for length in submission_df\n",
    "    if len(submission_df) != len(answer_df):\n",
    "        raise ValueError(\"The submission dataframe wrong length.\")\n",
    "\n",
    "    # Convert position data to numpy arrays for efficient computation\n",
    "    answer_positions = answer_df.iloc[:, 2:].to_numpy()  # Excluding ID, img_path, and type columns\n",
    "    submission_positions = submission_df.iloc[:, 1:].to_numpy()  # Excluding ID column\n",
    "\n",
    "    # Initialize the dictionary to hold accuracies\n",
    "    accuracies = {}\n",
    "\n",
    "    # Define combinations for 2x2 and 3x3 puzzles\n",
    "    combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "    combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "\n",
    "    # 1x1 Puzzle Accuracy\n",
    "    accuracies['1x1'] = np.mean(answer_positions == submission_positions)\n",
    "\n",
    "    # Calculate accuracies for 2x2, 3x3, and 4x4 puzzles\n",
    "    for size in range(2, 5):  # Loop through sizes 2, 3, 4\n",
    "        correct_count = 0  # Initialize counter for correct full sub-puzzles\n",
    "        total_subpuzzles = 0\n",
    "\n",
    "        # Iterate through each sample's puzzle\n",
    "        for i in range(len(answer_df)):\n",
    "            puzzle_a = answer_positions[i].reshape(4, 4)\n",
    "            puzzle_s = submission_positions[i].reshape(4, 4)\n",
    "            combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "\n",
    "            # Calculate the number of correct sub-puzzles for this size within a 4x4\n",
    "            for start_row, start_col in combinations:\n",
    "                rows = slice(start_row, start_row + size)\n",
    "                cols = slice(start_col, start_col + size)\n",
    "                if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                    correct_count += 1\n",
    "                total_subpuzzles += 1\n",
    "\n",
    "        accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "\n",
    "    score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NfeeL8hE958w"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, mask_ratio = 0.0, pretrained = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        deit3 = timm.create_model('deit3_base_patch16_384', pretrained = pretrained)\n",
    "\n",
    "        self.patch_embed = deit3.patch_embed\n",
    "        self.cls_token = deit3.cls_token\n",
    "        self.blocks = deit3.blocks\n",
    "        self.norm = deit3.norm\n",
    "\n",
    "        self.jigsaw = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 24*24)\n",
    "        )\n",
    "\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "\n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "\n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        # target = einops.repeat(self.target, 'L -> N L', N=N)\n",
    "        # target = target.to(x.device)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep] # N, len_keep\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "        target_masked = ids_keep\n",
    "\n",
    "        return x_masked, target_masked\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x, target = self.random_masking(x, self.mask_ratio)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        return x.reshape(-1, 24*24), target.reshape(-1)\n",
    "\n",
    "    def forward_test(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IRstRf3x-qKU"
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data_path, mode='train', transform=None):\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(os.path.join(self.data_path, row['img_path']))\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            image = self.reset_image(image, shuffle_order)\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        elif self.mode == 'test':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = Image.open(os.path.join(self.data_path, row['img_path']))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    def reset_image(self, image, shuffle_order):\n",
    "        c, h, w = image.shape\n",
    "        block_h, block_w = h//4, w//4\n",
    "        image_src = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_src[h_idx][w_idx] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle+1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle+1)]\n",
    "        image_src = np.concatenate([np.concatenate(image_row, -1) for image_row in image_src], -2)\n",
    "        return image_src.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0qkpooAl-NCU"
   },
   "outputs": [],
   "source": [
    "def build_transform(is_train):\n",
    "    if is_train:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        transform = create_transform(\n",
    "            input_size = (384, 384),\n",
    "            is_training = True,\n",
    "            color_jitter = 0.3,\n",
    "            auto_augment = 'rand-m9-mstd0.5-inc1',\n",
    "            interpolation= 'bicubic',\n",
    "            re_prob= 0.25,\n",
    "            re_mode= 'pixel',\n",
    "            re_count= 1,\n",
    "        )\n",
    "        return transform\n",
    "\n",
    "    t = []\n",
    "    t.append(transforms.Resize((384,384), interpolation=3))\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JtJM0YJgADGH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DATA/train.csv')\n",
    "train_df = df.iloc[:-6000]\n",
    "valid_df = df.iloc[-6000:]\n",
    "\n",
    "train_transform = build_transform(is_train = True)\n",
    "valid_transform = build_transform(is_train = False)\n",
    "\n",
    "train_dataset = JigsawDataset(df = train_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'train',\n",
    "                              transform = train_transform)\n",
    "valid_dataset = JigsawDataset(df = valid_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'test',\n",
    "                              transform = valid_transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = True\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ulQX6-h_A99y"
   },
   "outputs": [],
   "source": [
    "model = Model(mask_ratio = 0.5)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=3e-5,\n",
    "                        weight_decay = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OE_vIv0hA_4v",
    "outputId": "4b99cb94-a636-4181-c701-8d28e9212a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "[0 / 1000] loss: 6.3710527420043945\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "for epoch in range(1, 11):\n",
    "    print('Epoch ', epoch)\n",
    "    st = time.time()\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds, targets = model(x)\n",
    "\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            print(f'[{i} / {len(train_dataloader)}] loss:', loss.item())\n",
    "    et = time.time()\n",
    "    print('Time elapsed: ', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1g66lBJCQw4"
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(valid_dataloader):\n",
    "        x = x.to('cuda')\n",
    "        out = model.forward_test(x)\n",
    "        out = out.argmax(dim=2).cpu().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "outs = np.vstack(outs)\n",
    "valid_pred_df = valid_df.copy().drop(columns=['img_path'])\n",
    "\n",
    "for I, (idx, row) in enumerate(tqdm(valid_pred_df.iterrows(), total=len(valid_df))):\n",
    "    w = outs[I].reshape(24,24)\n",
    "    CNT_ROW = np.zeros((4,4,4), dtype=np.int32)\n",
    "    CNT_COL = np.zeros((4,4,4), dtype=np.int32)\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            ROW = i // 6\n",
    "            COL = j // 6\n",
    "            v = w[i][j]\n",
    "            CNT_ROW[ROW][COL][v // 24 // 6] += 1\n",
    "            CNT_COL[ROW][COL][v % 24 // 6] += 1\n",
    "    ans = CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1\n",
    "    ans = ans.reshape(16)\n",
    "    ans = list(map(str, ans))\n",
    "    valid_pred_df.loc[idx, '1':'16'] = ans\n",
    "score = calc_puzzle(valid_df, valid_pred_df)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
