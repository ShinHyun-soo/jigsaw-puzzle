{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {
    "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {
    "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67xr8MgXW9ue",
   "metadata": {
    "id": "67xr8MgXW9ue"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {
    "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
   },
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {
    "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':320,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':64,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {
    "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
   },
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {
    "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {
    "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {
    "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train0.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d1e99-e723-4eb8-973c-b7eb2f8a771a",
   "metadata": {
    "id": "ad2d1e99-e723-4eb8-973c-b7eb2f8a771a"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbcd2bc-6324-4cf3-8032-05080b019c5f",
   "metadata": {
    "id": "dbbcd2bc-6324-4cf3-8032-05080b019c5f"
   },
   "outputs": [],
   "source": [
    "# Train / Validation Split (70% : 30%)\n",
    "train_len = int(len(train_df) * 0.7)\n",
    "val_df = train_df.iloc[train_len:]\n",
    "train_df = train_df.iloc[:train_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca4c3bb-d300-4c2a-9147-94d90e6faab6",
   "metadata": {
    "id": "3ca4c3bb-d300-4c2a-9147-94d90e6faab6"
   },
   "outputs": [],
   "source": [
    "train_labels = train_df.iloc[:,2:].values.reshape(-1, 4, 4)\n",
    "val_labels = val_df.iloc[:,2:].values.reshape(-1, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd787b46-3bf0-4f36-9dec-69a03bf921e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1704381696534,
     "user": {
      "displayName": "Hyun-soo Shin",
      "userId": "02566596703701289040"
     },
     "user_tz": -540
    },
    "id": "bd787b46-3bf0-4f36-9dec-69a03bf921e0",
    "outputId": "435168e5-0525-4049-b9bd-99860831349f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146998, 4, 4), (63000, 4, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {
    "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e"
   },
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {
    "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transform=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "\n",
    "        # PIL 이미지로 불러오기\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = torch.tensor(self.label_list[index], dtype=torch.long) - 1\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01b4067-0669-44a9-bbbc-3065d8cb00c2",
   "metadata": {
    "id": "c01b4067-0669-44a9-bbbc-3065d8cb00c2"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {
    "id": "9d880481-1965-499d-9caa-fdfa8526f789"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df['img_path'].values, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_df['img_path'].values, val_labels, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "test_dataset = CustomDataset(test_df['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13766,
     "status": "ok",
     "timestamp": 1704381722337,
     "user": {
      "displayName": "Hyun-soo Shin",
      "userId": "02566596703701289040"
     },
     "user_tz": -540
    },
    "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
    "outputId": "7ab044a1-6234-4621-e7b0-2e83548488d3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet3(nn.Module):\n",
    "    def __init__(self,DSV=True):\n",
    "        super(UNet3,self).__init__()\n",
    "\n",
    "        self.DSV = DSV\n",
    "        def cbr(in_channels, out_channels, kernel_size = 3, stride = 1):\n",
    "            layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,kernel_size,stride,1),\n",
    "                #nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Conv2d(out_channels,out_channels,kernel_size,stride,1),\n",
    "                #nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            return layers\n",
    "\n",
    "        self.h = nn.Sequential(\n",
    "            nn.Conv2d(320,320,3,1,1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(320,320,3,1,1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        self.enc0 = cbr(1,64)\n",
    "        self.enc1 = cbr(64,128)\n",
    "        self.enc2 = cbr(128,256)\n",
    "        self.enc3 = cbr(256,512)\n",
    "        self.enc4 = cbr(512,1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.enc0_dec0 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,3,1,1)\n",
    "        )\n",
    "        self.enc0_dec1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64,64,3,1,1)\n",
    "        )\n",
    "        self.enc0_dec2 = nn.Sequential(\n",
    "            nn.MaxPool2d(4,4),\n",
    "            nn.Conv2d(64,64,3,1,1)\n",
    "        )\n",
    "        self.enc0_dec3 = nn.Sequential(\n",
    "            nn.MaxPool2d(8,8),\n",
    "            nn.Conv2d(64,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc1_dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128,64,3,1,1)\n",
    "        )\n",
    "        self.enc1_dec2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128,64,3,1,1)\n",
    "        )\n",
    "        self.enc1_dec3 = nn.Sequential(\n",
    "            nn.MaxPool2d(4,4),\n",
    "            nn.Conv2d(128,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc2_dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256,64,3,1,1)\n",
    "        )\n",
    "        self.enc2_dec3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(256,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc3_dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512,64,3,1,1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.dec_up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(320,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.dec_up4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear'),\n",
    "            nn.Conv2d(320,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.dec_up8 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=8, mode='bilinear'),\n",
    "            nn.Conv2d(320,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc4_up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(1024,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc4_up4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear'),\n",
    "            nn.Conv2d(1024,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc4_up8 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=8, mode='bilinear'),\n",
    "            nn.Conv2d(1024,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.enc4_up16 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=16, mode='bilinear'),\n",
    "            nn.Conv2d(1024,64,3,1,1)\n",
    "        )\n",
    "\n",
    "        self.result1 = nn.Sequential(\n",
    "            nn.Conv2d(320,1,3,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.result2 = nn.Sequential(\n",
    "            nn.Conv2d(1024,1,3,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        enc0 = self.enc0(x)\n",
    "        pool1 = self.pool(enc0)\n",
    "\n",
    "        enc1 = self.enc1(pool1)\n",
    "        pool2 = self.pool(enc1)\n",
    "\n",
    "        enc2 = self.enc2(pool2)\n",
    "        pool3 = self.pool(enc2)\n",
    "\n",
    "        enc3 = self.enc3(pool3)\n",
    "        pool4 = self.pool(enc3)\n",
    "\n",
    "        enc4 = self.enc4(pool4)\n",
    "\n",
    "        dec3 = self.h(torch.cat([self.enc0_dec3(enc0),self.enc1_dec3(enc1),self.enc2_dec3(enc2),self.enc3_dec3(enc3),self.enc4_up2(enc4)],1))\n",
    "        dec2 = self.h(torch.cat([self.enc0_dec2(enc0),self.enc1_dec2(enc1),self.enc2_dec2(enc2),self.dec_up2(dec3),self.enc4_up4(enc4)],1))\n",
    "        dec1 = self.h(torch.cat([self.enc0_dec1(enc0),self.enc1_dec1(enc1),self.dec_up2(dec2),self.dec_up4(dec3),self.enc4_up8(enc4)],1))\n",
    "        dec0 = self.h(torch.cat([self.enc0_dec0(enc0),self.dec_up2(dec1),self.dec_up4(dec2),self.dec_up8(dec3),self.enc4_up16(enc4)],1))\n",
    "\n",
    "        out = []\n",
    "        if self.DSV:\n",
    "            out.append(self.result1(dec0))\n",
    "            out.append(self.result1(dec1))\n",
    "            out.append(self.result1(dec2))\n",
    "            out.append(self.result1(dec3))\n",
    "            out.append(self.result2(enc4))\n",
    "        else:\n",
    "            out.append(self.result1(dec0))\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {
    "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {
    "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_acc = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val ACC : [{_val_acc:.5f}]')\n",
    "\n",
    "        if best_val_acc < _val_acc:\n",
    "            best_val_acc = _val_acc\n",
    "            best_model = model\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a0bf01-27cd-4faf-93b1-3aa8a37be01c",
   "metadata": {
    "id": "24a0bf01-27cd-4faf-93b1-3aa8a37be01c"
   },
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(imgs)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            # 정확도 계산을 위한 예측 레이블 추출\n",
    "            predicted_labels = torch.argmax(output, dim=1)\n",
    "\n",
    "            # 샘플 별 정확도 계산\n",
    "            for predicted_label, label in zip(predicted_labels, labels):\n",
    "                val_acc.append(((predicted_label == label).sum() / 16).item())\n",
    "\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_acc = np.mean(val_acc)\n",
    "\n",
    "    return _val_loss, _val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {
    "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
   },
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426,
     "referenced_widgets": [
      "fe0efc562a674c39847a12c26a11b60c",
      "c7def1e1c1f54a1d890b7e805e57e256",
      "3634bf4fd2f54937b70da718cdaa3e99",
      "244aa8097f8343cba52fe995521088c2",
      "4d41c62e860c418faaba1fb64f69c159",
      "16430dec2eed403ca1453b745e178d3e",
      "e86435a267e04b72a39d90c5bc2b03c9",
      "2140e8d774e4430e8db5d54f16e1b1f5",
      "f073b1fa2d08470684b6cc0cd1be81e5",
      "f117ef9bae7a45b0804bb69b8b42452f",
      "36fa6147eb9241e09f455da7cf4b2c15"
     ]
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "error",
     "timestamp": 1704381763301,
     "user": {
      "displayName": "Hyun-soo Shin",
      "userId": "02566596703701289040"
     },
     "user_tz": -540
    },
    "id": "86142d9a-68b7-4d04-8423-49d28025411d",
    "outputId": "8b2c9e5b-894c-492b-abe6-a0e435426c69",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e50aa812a47ec816dcf227b1c7f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 3, 3], expected input[64, 3, 320, 320] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet3()\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEARNING_RATE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m infer_model \u001b[38;5;241m=\u001b[39m train(model, optimizer, train_loader, val_loader, device)\n",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 132\u001b[0m, in \u001b[0;36mUNet3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m--> 132\u001b[0m     enc0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc0(x)\n\u001b[0;32m    133\u001b[0m     pool1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(enc0)\n\u001b[0;32m    135\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc1(pool1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[64, 3, 320, 320] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "model = UNet3()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14375e55-9c73-443d-a836-2ec9bc20faee",
   "metadata": {
    "id": "14375e55-9c73-443d-a836-2ec9bc20faee"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e3678-a3c7-4f32-8e4a-253b1321b4c3",
   "metadata": {
    "id": "200e3678-a3c7-4f32-8e4a-253b1321b4c3"
   },
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "\n",
    "            output = model(imgs)\n",
    "\n",
    "            # 정확도 계산을 위한 예측 레이블 추출\n",
    "            predicted_labels = torch.argmax(output, dim=1).view(-1, 16)\n",
    "            predicted_labels = predicted_labels.cpu().detach().numpy()\n",
    "\n",
    "            preds.extend(predicted_labels)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8f47f-56fe-41f5-9daf-a550d72e1f78",
   "metadata": {
    "id": "d2f8f47f-56fe-41f5-9daf-a550d72e1f78"
   },
   "outputs": [],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad9d51-f03c-4e90-be42-e4e1824b07da",
   "metadata": {
    "id": "ffad9d51-f03c-4e90-be42-e4e1824b07da"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfc7bc-3436-40ea-864b-d6b1a721011a",
   "metadata": {
    "id": "febfc7bc-3436-40ea-864b-d6b1a721011a"
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511aff4-c7d4-48eb-ae9b-f63171304f36",
   "metadata": {
    "id": "7511aff4-c7d4-48eb-ae9b-f63171304f36"
   },
   "outputs": [],
   "source": [
    "submit.iloc[:, 1:] = preds\n",
    "submit.iloc[:, 1:] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2838bc5-dfc9-4615-8677-28aa8445984c",
   "metadata": {
    "id": "a2838bc5-dfc9-4615-8677-28aa8445984c"
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16430dec2eed403ca1453b745e178d3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2140e8d774e4430e8db5d54f16e1b1f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244aa8097f8343cba52fe995521088c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f117ef9bae7a45b0804bb69b8b42452f",
      "placeholder": "​",
      "style": "IPY_MODEL_36fa6147eb9241e09f455da7cf4b2c15",
      "value": " 0/766 [00:00&lt;?, ?it/s]"
     }
    },
    "3634bf4fd2f54937b70da718cdaa3e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2140e8d774e4430e8db5d54f16e1b1f5",
      "max": 766,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f073b1fa2d08470684b6cc0cd1be81e5",
      "value": 0
     }
    },
    "36fa6147eb9241e09f455da7cf4b2c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d41c62e860c418faaba1fb64f69c159": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7def1e1c1f54a1d890b7e805e57e256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16430dec2eed403ca1453b745e178d3e",
      "placeholder": "​",
      "style": "IPY_MODEL_e86435a267e04b72a39d90c5bc2b03c9",
      "value": "  0%"
     }
    },
    "e86435a267e04b72a39d90c5bc2b03c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f073b1fa2d08470684b6cc0cd1be81e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f117ef9bae7a45b0804bb69b8b42452f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe0efc562a674c39847a12c26a11b60c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7def1e1c1f54a1d890b7e805e57e256",
       "IPY_MODEL_3634bf4fd2f54937b70da718cdaa3e99",
       "IPY_MODEL_244aa8097f8343cba52fe995521088c2"
      ],
      "layout": "IPY_MODEL_4d41c62e860c418faaba1fb64f69c159"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
